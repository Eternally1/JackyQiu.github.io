---
title: 从零开始学习爬取微博数据
date: 2018-07-27 14:32:47
categories: 
- weibo
tags: ["weibo"]
---

# 1. 微博高级检索工具
首先，使用微博进行搜索，在搜索结果中可以看到下图中的结果。前提是需要已经登录了微博，如果没有登录，那么就不会有“高级搜索”的。

![高级搜索](/images/weibo/weibo_04.png)

之后点击之后的具体界面如下图

![高级搜索](/images/weibo/weibo_03.png)

这里主要说一下在对这些内容进行编码的时候遇到的问题。首先看一下高级检索工具得到的URL地址   
http://s.weibo.com/weibo/%25E9%25B9%25BF%25E6%2599%2597&region=custom:42:1&typeall=1&suball=1&timescope=custom:2018-07-26-11:2018-07-27-13&Refer=g  
将他们切分开然后进行对应的分析说明  

- %25E9%25B9%25BF%25E6%2599%2597   这一部分其实就是关键词“鹿晗”进行编码之后形成的
- region=custom:42:1  这一部分是地点，应该有对应的编码表，我选择的是湖北 襄阳
- typeall=1  这个就是“类型”，1表示全部，hot表示热门，对应的其他的可以及其了解一下
- suuall=1  就是“包含”，1表示全部
- timescope=custom:2018-07-26-11:2018-07-27-13  这里就是时间范围了，最小粒度是小时，这里就是从26号的11时到27号的13时。
- &Refer=g   这个就不是很清楚了。

首先是关键词，微博对关键词的编码是进行了两次，如下，其中s_code1是通过高级搜索工具进行搜索的时候得到的关键字对应的编码，需要解码两次得到想要的结果。
```Python
import urllib
s_code1 = "%25E9%25B9%25BF%25E6%2599%2597"
s_code2 = urllib.parse.unquote(s_code1)
# 解码
print(urllib.parse.unquote(s_code2))

```

接着是关于高级检索的时间设置问题，当设置检索的时间为2018-07-26-11至2018-07-26-12，此时搜索出来的微博是从11:00--12:59之间的微博，这需要注意一下。因此如果想获取一个小时内的数据，应该设置的小时是一样的。

# 2. 微博爬虫
其实写这一部分的时候微博爬虫的代码还没有写出来，主要说明一下目前遇到的一些问题，当这些问题解决了之后应该就容易了。  
首先，微博的反爬虫机制是比较强大的，主要是关于微博账号和IP地址的问题。因为代理IP的价格问题等因素，这里主要是想准备采用多个微博账号轮流进行抓取，同时设置延迟。  
使用多个微博账号，需要首先获取这些微博账号的Cookie，之后存储起来，然后轮流进行数据的获取，但是这样有一个问题就是，轮流抓取的话如何记录抓取的状态，目前还没有解决。  

## 2.1 使用的python库
因为在进行微博网站分析的时候，在搜索结果的源代码中发现没有对应的想获取的信息，有些数据是通过动态加载的，通过JS或者Ajax代码进行加载的。通过分析网络请求发现，也不是通过Ajax加载的，在Ajax请求中，只有一个md5_mapping_file.json文件，不知道用处。因此只能等页面加载完成之后再获取数据，而正好有一个库文件Selenium可以解决这种情况。
```Python
from selenium import webdriver
from bs4 import BeautifulSoup   # 页面解析工具

driver = webdriver.Firefox()    # 加载火狐浏览器的驱动
url = "http://s.weibo.com/weibo/%25E9%2595%25BF%25E6%2598%25A5%25E7%2596%25AB%25E8%258B%2597&typeall=1&suball=1&timescope=custom:2018-07-15-11:2018-07-15-15&Refer=g"
driver.get(url,cookiess=Cookie)
html = driver.page_source         # 此时已经获取到加载之后的数据，接着开始使用BeautifulSoup进行数据的获取
soup = BeautifulSoup(html,'lxml')
```
其中selenium可以通过pip进行安装，而对应的浏览器的驱动可以在这里下载[firefoxDriver](https://npm.taobao.org/mirrors/geckodriver/)，需要注意的是和自己已经安装的浏览器的版本已经Selenium的版本适配。通过在命令行下使用pip freeze可以查看已经安装的selenium的版本。
【注意】我在使用chromeDriver的时候一直报错，可能就是版本问题，之后重新使用了firefoxDriver就好了。




